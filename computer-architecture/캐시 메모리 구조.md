# 캐시 메모리 구조 (Cache Memory)

## 1. 캐시 메모리란?
- CPU와 메인 메모리(RAM) 사이에 위치하는 **고속 메모리**  
- 자주 사용하는 데이터나 명령어를 저장하여 CPU 접근 속도를 향상시킴  
- **지역성(Locality) 원리**에 기반:
  - **시간적 지역성 (Temporal Locality)**: 최근에 사용한 데이터는 곧 다시 사용될 가능성이 큼
  - **공간적 지역성 (Spatial Locality)**: 참조한 주소 근처의 데이터도 사용될 가능성이 큼

---

## 2. 캐시 계층 구조
- 속도와 용량에 따라 **L1, L2, L3 캐시**로 구분
1. **L1 캐시**  
   - CPU 코어 내부에 존재  
   - 용량 작음(수십 KB), 속도 가장 빠름  
   - 데이터 캐시와 명령어 캐시로 분리되는 경우 많음
2. **L2 캐시**  
   - CPU 코어 내부 또는 근처에 존재  
   - L1보다 크고 느림 (수백 KB ~ 수 MB)  
   - 여러 코어가 공유하거나, 각 코어마다 독립적으로 존재
3. **L3 캐시**  
   - CPU 전체가 공유  
   - 수 MB~수십 MB 용량, 속도는 L2보다 느리지만 RAM보다는 빠름

---

## 3. 캐시 매핑 방식
CPU가 요청한 메모리 주소가 캐시에 어떻게 저장되는지를 결정하는 방식
- **직접 매핑 (Direct Mapping)**  
  - 메모리 블록이 캐시의 특정 한 위치에만 저장 가능  
  - 구현이 단순하지만 충돌(Cache Miss)이 자주 발생
- **연관 매핑 (Associative Mapping)**  
  - 메모리 블록이 캐시의 어떤 라인에도 저장 가능  
  - 유연하지만 검색 속도가 느릴 수 있음
- **집합 연관 매핑 (Set-Associative Mapping)**  
  - 캐시를 여러 집합(Set)으로 나누고, 각 집합 내에서는 연관 매핑 사용  
  - 직접 매핑과 연관 매핑의 절충안 → 실제 CPU에서 주로 사용

---

## 4. 캐시 교체 알고리즘 (Cache Replacement Policy)
캐시가 가득 찼을 때 어떤 블록을 교체할지 결정하는 정책
- **LRU (Least Recently Used)**: 가장 오랫동안 사용하지 않은 데이터 교체  
- **FIFO (First In First Out)**: 가장 먼저 들어온 데이터를 교체  
- **LFU (Least Frequently Used)**: 사용 빈도가 가장 낮은 데이터 교체  
- **Random**: 무작위로 선택해 교체 (하드웨어 구현 단순)

---

## 5. 캐시 적중/실패
- **캐시 히트(Cache Hit)**: CPU가 요청한 데이터가 캐시에 존재 → 빠른 접근 가능  
- **캐시 미스(Cache Miss)**: 데이터가 캐시에 없어 메인 메모리에서 가져와야 함 → 속도 저하  
  - **Cold Miss**: 처음 접근할 때 발생  
  - **Conflict Miss**: 매핑 충돌로 발생  
  - **Capacity Miss**: 캐시 용량 부족으로 발생
